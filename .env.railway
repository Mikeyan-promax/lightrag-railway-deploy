### LightRAG Railway 部署环境配置
### 基于原始.env文件结构，适配Railway平台

###########################
### Server Configuration
###########################
HOST=0.0.0.0
PORT=${PORT}
WEBUI_TITLE='LightRAG Railway KB'
WEBUI_DESCRIPTION="Railway-powered Graph Based RAG System"
WORKERS=2
CORS_ORIGINS=*

###########################
### 阿里云RDS PostgreSQL 数据库配置
###########################
# 阿里云RDS PostgreSQL连接信息 (URL编码密码)
DATABASE_URL=${DATABASE_URL}

# 分离的PostgreSQL配置参数
POSTGRES_HOST=${POSTGRES_HOST}
POSTGRES_PORT=${POSTGRES_PORT}
POSTGRES_USER=${POSTGRES_USER}
POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
POSTGRES_DATABASE=${POSTGRES_DATABASE}
POSTGRES_MAX_CONNECTIONS=8

# 原Supabase配置（已禁用）
# SUPABASE_URL=https://your-project-id.supabase.co
# SUPABASE_ANON_KEY=your_supabase_anon_key_here
# SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key_here

###########################
### AI 模型配置
###########################
# OpenAI 配置
OPENAI_API_KEY=${OPENAI_API_KEY}
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4o-mini

# 嵌入模型配置
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIM=1536

###########################
### Server Configuration
###########################
HOST=0.0.0.0
PORT=${PORT}
WEBUI_TITLE='LightRAG Railway KB'
WEBUI_DESCRIPTION="Railway-powered Graph Based RAG System"
WORKERS=2
CORS_ORIGINS=*

### 安全配置
# 生成随机密钥: openssl rand -hex 32
SECRET_KEY=${SECRET_KEY}
ALLOWED_HOSTS=*

### Redis 配置 (Railway内部服务)
REDIS_URL=${REDIS_URL}
REDIS_PASSWORD=${REDIS_PASSWORD}
REDIS_DB=0

### Optional SSL Configuration (Railway自动处理HTTPS)
# SSL=false
# SSL_CERTFILE=/path/to/cert.pem
# SSL_KEYFILE=/path/to/key.pem

### Directory Configuration (defaults to current working directory)
### Default value is ./inputs and ./rag_storage
INPUT_DIR=./inputs
WORKING_DIR=./rag_storage

### 文件上传配置
MAX_FILE_SIZE=50
ALLOWED_FILE_TYPES=.txt,.pdf,.docx,.md,.json

### Ollama Emulating Model and Tag
# OLLAMA_EMULATING_MODEL_NAME=lightrag
OLLAMA_EMULATING_MODEL_TAG=latest

### Max nodes return from grap retrieval in webui
MAX_GRAPH_NODES=500

### Logging level
LOG_LEVEL=INFO
VERBOSE=False
LOG_MAX_BYTES=10485760
LOG_BACKUP_COUNT=3
### Logfile location (defaults to current working directory)
# LOG_DIR=/path/to/log/directory

#####################################
### Login and API-Key Configuration
#####################################
AUTH_ACCOUNTS=${AUTH_ACCOUNTS}
TOKEN_SECRET=${TOKEN_SECRET}
TOKEN_EXPIRE_HOURS=48
GUEST_TOKEN_EXPIRE_HOURS=24
JWT_ALGORITHM=HS256

### API-Key to access LightRAG Server API
LIGHTRAG_API_KEY=${LIGHTRAG_API_KEY}
WHITELIST_PATHS=/health,/api/*

######################################################################################
### Query Configuration
###
### How to control the context lenght sent to LLM:
###    MAX_ENTITY_TOKENS + MAX_RELATION_TOKENS < MAX_TOTAL_TOKENS
###    Chunk_Tokens = MAX_TOTAL_TOKENS - Actual_Entity_Tokens - Actual_Reation_Tokens
######################################################################################
# LLM responde cache for query (Not valid for streaming response)
ENABLE_LLM_CACHE=true
COSINE_THRESHOLD=0.2
### Number of entities or relations retrieved from KG
TOP_K=30
### Maxmium number or chunks for naive vactor search
CHUNK_TOP_K=8
### control the actual enties send to LLM
MAX_ENTITY_TOKENS=8000
### control the actual relations send to LLM
MAX_RELATION_TOKENS=8000
### control the maximum tokens send to LLM (include entities, raltions and chunks)
MAX_TOTAL_TOKENS=20000
### maximum number of related chunks per source entity or relation (higher values increase re-ranking time)
RELATED_CHUNK_NUMBER=3

### Reranker configuration (Set ENABLE_RERANK to true in reranking model is configed)
ENABLE_RERANK=False
### Minimum rerank score for document chunk exclusion (set to 0.0 to keep all chunks, 0.6 or above if LLM is not strong enought)
MIN_RERANK_SCORE=0.0
### Rerank model configuration (required when ENABLE_RERANK=True)
# RERANK_MODEL=jina-reranker-v2-base-multilingual
# RERANK_BINDING_HOST=https://api.jina.ai/v1/rerank
# RERANK_BINDING_API_KEY=your_rerank_api_key_here

########################################
### Document processing configuration
########################################
### Language: English, Chinese, French, German ...
SUMMARY_LANGUAGE=Chinese
ENABLE_LLM_CACHE_FOR_EXTRACT=true
### Chunk size for document splitting, 500~1500 is recommended
CHUNK_SIZE=1000
CHUNK_OVERLAP_SIZE=100
### Entity and relation summarization configuration
### Number of duplicated entities/edges to trigger LLM re-summary on merge (at least 3 is recommented)， and max tokens send to LLM
FORCE_LLM_SUMMARY_ON_MERGE=4
MAX_TOKENS=8000
### Maximum number of entity extraction attempts for ambiguous content
MAX_GLEANING=1

###############################
### Concurrency Configuration
###############################
### Max concurrency requests of LLM (for both query and document processing)
MAX_ASYNC=2
### Number of parallel processing documents(between 2~10, MAX_ASYNC/3 is recommended)
MAX_PARALLEL_INSERT=1
### Max concurrency requests for Embedding
EMBEDDING_FUNC_MAX_ASYNC=4
### Num of chunks send to Embedding in single request
EMBEDDING_BATCH_NUM=8

#######################
### LLM Configuration
#######################
### Some models like o1-mini require temperature to be set to 1, some LLM can fall into output loops with low temperature
TEMPERATURE=0.7

### LLM Binding type: openai, ollama, lollms, azure_openai
LLM_BINDING=openai
LLM_MODEL=${LLM_MODEL}
LLM_BINDING_HOST=${LLM_BINDING_HOST}
LLM_BINDING_API_KEY=${LLM_BINDING_API_KEY}

### Most Commont Parameters for Ollama Server
### see also env.ollama-binding-options.example for fine tuning ollama
### OLLAMA_LLM_NUM_CTX must be larger than MAX_TOTAL_TOKENS + 2000
# OLLAMA_LLM_NUM_CTX=32768
### Time out in seconds, None for infinite timeout
TIMEOUT=180

### Optional for Azure
# AZURE_OPENAI_API_VERSION=2024-08-01-preview
# AZURE_OPENAI_DEPLOYMENT=gpt-4o

####################################################################################
### Embedding Configuration (Should not be changed after the first file processed)
####################################################################################
### Embedding Binding type: openai, ollama, lollms, azure_openai, jina

### see also env.ollama-binding-options.example for fine tuning ollama
EMBEDDING_BINDING=${EMBEDDING_BINDING}
EMBEDDING_MODEL=${EMBEDDING_MODEL}
EMBEDDING_DIM=${EMBEDDING_DIM}
EMBEDDING_BINDING_API_KEY=${EMBEDDING_BINDING_API_KEY}
# If the embedding service is deployed within the same Docker stack, use host.docker.internal instead of localhost
EMBEDDING_BINDING_HOST=${EMBEDDING_BINDING_HOST}

### OpenAI compatible
# EMBEDDING_BINDING=openai
# EMBEDDING_MODEL=text-embedding-3-large
# EMBEDDING_DIM=3072
# EMBEDDING_BINDING_HOST=https://api.openai.com
# EMBEDDING_BINDING_API_KEY=your_api_key

### Optional for Azure
# AZURE_EMBEDDING_DEPLOYMENT=text-embedding-3-large
# AZURE_EMBEDDING_API_VERSION=2023-05-15
# AZURE_EMBEDDING_ENDPOINT=your_endpoint
# AZURE_EMBEDDING_API_KEY=your_api_key

### Jina AI Embedding
# EMBEDDING_BINDING=jina
# EMBEDDING_BINDING_HOST=https://api.jina.ai/v1/embeddings
# EMBEDDING_MODEL=jina-embeddings-v4
# EMBEDDING_DIM=2048
# EMBEDDING_BINDING_API_KEY=your_api_key

####################################################################
### WORKSPACE setting workspace name for all storage types
### in the purpose of isolating data from LightRAG instances.
### Valid workspace name constraints: a-z, A-Z, 0-9, and _
####################################################################
WORKSPACE=${WORKSPACE}

############################
### Data storage selection
############################
### Default storage (Recommended for small scale deployment)
# LIGHTRAG_KV_STORAGE=JsonKVStorage
# LIGHTRAG_DOC_STATUS_STORAGE=JsonDocStatusStorage
# LIGHTRAG_GRAPH_STORAGE=NetworkXStorage
# LIGHTRAG_VECTOR_STORAGE=NanoVectorDBStorage

### Redis Storage (Recommended for production deployment)
# LIGHTRAG_KV_STORAGE=RedisKVStorage
# LIGHTRAG_DOC_STATUS_STORAGE=RedisDocStatusStorage

### Vector Storage (Recommended for production deployment)
# LIGHTRAG_VECTOR_STORAGE=MilvusVectorDBStorage
# LIGHTRAG_VECTOR_STORAGE=QdrantVectorDBStorage
# LIGHTRAG_VECTOR_STORAGE=FaissVectorDBStorage

### Graph Storage (Recommended for production deployment)
# LIGHTRAG_GRAPH_STORAGE=Neo4JStorage
# LIGHTRAG_GRAPH_STORAGE=MemgraphStorage

### PostgreSQL 存储配置 (默认推荐配置，一体式数据库)
LIGHTRAG_KV_STORAGE=PGKVStorage
LIGHTRAG_DOC_STATUS_STORAGE=PGDocStatusStorage
# LIGHTRAG_GRAPH_STORAGE=PGGraphStorage  # 知识图谱功能已禁用
LIGHTRAG_VECTOR_STORAGE=PGVectorStorage

### MongoDB (Vector storage only available on Atlas Cloud)
# LIGHTRAG_KV_STORAGE=MongoKVStorage
# LIGHTRAG_DOC_STATUS_STORAGE=MongoDocStatusStorage
# LIGHTRAG_GRAPH_STORAGE=MongoGraphStorage
# LIGHTRAG_VECTOR_STORAGE=MongoVectorDBStorage

### PostgreSQL Configuration - 阿里云RDS连接
POSTGRES_HOST=${POSTGRES_HOST}
POSTGRES_PORT=${POSTGRES_PORT}
POSTGRES_USER=${POSTGRES_USER}
POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
POSTGRES_DATABASE=${POSTGRES_DATABASE}
POSTGRES_MAX_CONNECTIONS=8
POSTGRES_SSL_MODE=require
# POSTGRES_WORKSPACE=forced_workspace_name

### PostgreSQL SSL Configuration (Optional)
# POSTGRES_SSL_MODE=require
# POSTGRES_SSL_CERT=/path/to/client-cert.pem
# POSTGRES_SSL_KEY=/path/to/client-key.pem
# POSTGRES_SSL_ROOT_CERT=/path/to/ca-cert.pem
# POSTGRES_SSL_CRL=/path/to/crl.pem

### Neo4j Configuration (已禁用，使用PostgreSQL)
# NEO4J_URI=neo4j+s://xxxxxxxx.databases.neo4j.io
# NEO4J_USERNAME=neo4j
# NEO4J_PASSWORD='your_password'
# NEO4J_MAX_CONNECTION_POOL_SIZE=100
# NEO4J_CONNECTION_TIMEOUT=30
# NEO4J_CONNECTION_ACQUISITION_TIMEOUT=30
# MAX_TRANSACTION_RETRY_TIME=30
# NEO4J_WORKSPACE=forced_workspace_name

### MongoDB Configuration (已禁用，使用PostgreSQL)
# MONGO_URI=mongodb://root:root@localhost:27017/
# #MONGO_URI=mongodb+srv://xxxx
# MONGO_DATABASE=LightRAG
# MONGODB_WORKSPACE=forced_workspace_name

### Milvus Configuration (已禁用，使用PostgreSQL)
# MILVUS_URI=http://localhost:19530
# MILVUS_DB_NAME=lightrag
# MILVUS_USER=root
# MILVUS_PASSWORD=your_password
# MILVUS_TOKEN=your_token
# MILVUS_WORKSPACE=forced_workspace_name

### Qdrant (已禁用，使用PostgreSQL)
# QDRANT_URL=http://localhost:6333
# QDRANT_API_KEY=your-api-key
# QDRANT_WORKSPACE=forced_workspace_name

### Redis (已禁用，使用PostgreSQL)
# REDIS_URI=redis://localhost:6379
# REDIS_SOCKET_TIMEOUT=30
# REDIS_CONNECT_TIMEOUT=10
# REDIS_MAX_CONNECTIONS=100
# REDIS_RETRY_ATTEMPTS=3
# REDIS_WORKSPACE=forced_workspace_name

### Memgraph Configuration (已禁用，使用PostgreSQL)
# MEMGRAPH_URI=bolt://localhost:7687
# MEMGRAPH_USERNAME=
# MEMGRAPH_PASSWORD=
# MEMGRAPH_DATABASE=memgraph
# MEMGRAPH_WORKSPACE=forced_workspace_name